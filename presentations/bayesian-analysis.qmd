---
title: "Introduction to Bayesian Analysis"
subtitle: "CMOR Lunch'n'Learn"
author: "Ross Wilson"
date: "2024-04-11"
date-format: "D MMMM YYYY"
format:
  revealjs:
    theme: [default, cmor.scss]
    title-slide-attributes: 
      data-background-image: "images/otago-pennant.png, images/cmor-banner.png, images/title-background.png"
      data-background-size: "7%, 25%, 100%"
      data-background-position: "3% 1%, bottom 1% left 50px,0 0"
      data-background-repeat: "no-repeat"
    template-partials:
      - styles.html
      - title-slide.html
    margin: 0.2
    footer: "[Return to CMOR Lunch'n'Learn presentations](../index.html)"
---
```{r setup}
library(tidyverse)
library(kableExtra, exclude = "group_rows")
```

## What is Bayesian analysis?

<br>

* A **probabilistic** approach to data analysis and interpretation

<br>

* How should we refine our prior beliefs about (say) a treatment effect, in light of data from a study?

<br>

* Traditional statistical analysis summarises what the data from *this study* tells us about the treatment effect;  
Bayesian analysis tells us how the data should change our opinion about the effect

<!-- * Bayesian analysis is about estimating/interpreting the *uncertainty* or *probability distribution* of parameters -->

<!-- <br> -->

<!-- * To understand this, we need a very brief background to probability theory -->

## What is probability?

<br>

What does it mean to say something has a probability of, say, 20%?

<br>

::: {.columns}

:::: {.column .fragment width="45%"}
**Relative frequency**

<br>

$\mathrm{Pr}(A) = \lim\limits_{n \to \infty} \frac{\text{# times } A \text{ occurs}}{n}$

<br>

::::: {.fragment}

If we repeatedly sample from a given situation, what proportion of times will the event occur?

:::::

::::

:::: {.column width="10%"}

::::

:::: {.column .fragment width="45%"}
**Subjective probability**

*A measure of certainty (or uncertainty) in an event*

::::: {.fragment}

* What is the probability it will rain in Dunedin tomorrow?

* What is the probability that exercise therapy is beneficial for a patient with OA?

:::::

::::

:::

## Conditional probability

<br>

* Probability is conditional on available information

::: {.incremental}

* What is the probability it will rain in Dunedin tomorrow?

  * $\mathrm{Pr}(\text{Rain tomorrow})$

  * $\mathrm{Pr}(\text{Rain tomorrow}\ |\ \text{Today's weather})$

  * $\mathrm{Pr}(\text{Rain tomorrow}\ |\ \text{Tomorrow's forecast})$

* Even the first (unconditional) probability is implicitly conditional on some information set  
(your general knowledge about Dunedin's rainfall patterns)

:::

## What is Bayesian analysis?

<br>

* Bayesian analysis is the process of updating these probabilities in light of new information

. . .

* That is, given new $\mathit{data}$, how should we get from

$$\mathrm{Pr}(A)$$

. . .

::: {style="text-align:center"}
to
:::

$$\mathrm{Pr}(A\ |\ \mathit{data})$$

<br>

## Bayes' Theorem:

<br>

$$\mathrm{Pr}(A | B) = \frac{\mathrm{Pr}(B | A) \mathrm{Pr}(A)}{\mathrm{Pr}(B)}$$

<br>

. . .

  * In a statistical model, we are usually interested in probability distributions over continuous covariates:

$$f(\theta | y) = \frac{f(y | \theta) f(\theta)}{f(y)}$$

  (updated knowledge about a parameter $\theta$ given data $y$)

## Bayes' Theorem

* Tells us how to calculate the 'posterior distribution' given:
  * an assumed data generating model
  * prior information/beliefs about the parameter(s)
  * current data

. . .

$$f(\theta | y) = \frac{f(y | \theta) f(\theta)}{f(y)}$$

. . .

$$\mathrm{Posterior} \propto \mathrm{Likelihood} \times \mathrm{Prior}$$

. . .

* Informally: updated belief = current evidence $\times$ prior evidence or belief

## Bayes' Theorem

* Conceptually,

  * we start with some beliefs about the parameters of interest
  
  * review those beliefs in light of the evidence at hand
  
  * and calculate an updated belief as a combination of the prior and the new evidence
  
```{r}
density_tbl <- tibble(
  theta = seq(0, 1, length.out = 99999),
  prior = dbeta(theta, 10, 10),
  likelihood = dbeta(theta, 9, 6),
  posterior = dbeta(theta, 19, 16)
)

ymax <- max(density_tbl$prior, density_tbl$likelihood, density_tbl$posterior)
```

```{r}
p1 <- ggplot(density_tbl, aes(theta)) +
    geom_area(aes(y = prior), linetype = 0, fill = "#8888FF66", stat = "identity", position = "identity") +
    scale_x_continuous(limits = c(0, 1)) +
    scale_y_continuous("Density", limits = c(0, ymax), expand = c(0, 0)) +
    theme(axis.line.y = element_blank(), axis.ticks.y = element_blank(), axis.text.y = element_blank(),
          axis.line.x = element_blank(), panel.grid = element_blank(),
          panel.background = element_blank(), plot.background = element_blank())
p2 <- p1 +
  geom_area(aes(y = likelihood), linetype = 0, fill = "#FF888866", stat = "identity", position = "identity")
p3 <- p2 +
  geom_area(aes(y = posterior), linetype = 0, fill = "#EE88CC66", stat = "identity", position = "identity")
ggsave("images/density-1.png", p1, width = 6, height = 4)
ggsave("images/density-2.png", p2, width = 6, height = 4)
ggsave("images/density-3.png", p3, width = 6, height = 4)
```

![](images/density-1.png){.absolute bottom=-60 left=230 width=675 .fragment .fade-in-then-out fragment-index=1}

![](images/density-2.png){.absolute bottom=-60 left=230 width=675 .fragment .fade-in-then-out fragment-index=2}

![](images/density-3.png){.absolute bottom=-60 left=230 width=675 .fragment fragment-index=3}

::: {.absolute bottom=180 left=430 .fragment fragment-index=1}
[Prior]{style="color:#9999FF;"}
:::


::: {.absolute bottom=130 left=750 .fragment fragment-index=2}
[Likelihood]{style="color:#FF9999;"}
:::


::: {.absolute bottom=300 left=650 .fragment fragment-index=3}
[Posterior]{style="color:#C76F8E;"}
:::
## Specifying priors

* Where do these 'priors' come from?

  * Previous research
  
  * Common sense/intuition?
  
  * 'Weakly informative' priors

::: {.fragment fragment-index=1}

* In most cases there is no 'correct' prior, and sensitivity to various plausible priors should be considered

:::
::: {.fragment fragment-index=2}

* The more data we have, the less the prior matters

:::

```{r}
density_tbl2 <- density_tbl |> 
  mutate(
  likelihood2 = dbeta(theta, 90, 60),
  posterior2 = dbeta(theta, 100, 70)
)

ymax2 <- max(density_tbl2$prior, density_tbl2$likelihood2, density_tbl2$posterior2)

p4 <- ggplot(density_tbl2, aes(theta)) +
    geom_area(aes(y = prior), linetype = 0, fill = "#8888FF66", stat = "identity", position = "identity") +
    scale_x_continuous(limits = c(0, 1)) +
    scale_y_continuous(NULL, limits = c(0, ymax2), expand = c(0, 0)) +
    theme(axis.line.y = element_blank(), axis.ticks.y = element_blank(), axis.text.y = element_blank(),
          axis.line.x = element_blank(), panel.grid = element_blank(),
          panel.background = element_blank(), plot.background = element_blank())
p5 <- p4 +
  geom_area(aes(y = likelihood2), linetype = 0, fill = "#FF888866", stat = "identity", position = "identity")
p6 <- p5 +
  geom_area(aes(y = posterior2), linetype = 0, fill = "#EE88CC66", stat = "identity", position = "identity")
ggsave("images/more-data-1.png", p4, width = 6, height = 10)
ggsave("images/more-data-2.png", p5, width = 6, height = 10)
ggsave("images/more-data-3.png", p6, width = 6, height = 10)
```

![](images/more-data-1.png){.absolute bottom=-60 left=410 width=600 .fragment .fade-in-then-out fragment-index=3}

![](images/more-data-2.png){.absolute bottom=-60 left=410 width=600 .fragment .fade-in-then-out fragment-index=4}

![](images/more-data-3.png){.absolute bottom=-60 left=410 width=600 .fragment fragment-index=5}

## Why Bayesian analysis? {.smaller}

* Our objective is usually to conclude something about the likely values of a treatment effect (or other outcome of interest)

* There is usually at least some prior evidence relevant to the research question

  * Ignoring this evidence limits our ability to draw appropriate conclusions from research
  
  * Explicitly incorporating prior evidence forces researchers, and users of research, to think carefully and be transparent about what external evidence, judgements, and assumptions should be included

. . .

* As we will see, Bayesian analysis can also be much more flexible than traditional approaches, both in what data can contribute to analysis and in the particular models that can be estimated

. . .

* Interpretation of Bayesian results is much more intuitive and applicable than most traditional statistical methods

## Presentation and interpretation

To be added - consider prior -> posterior interpretation, so need to consider sensitivity to prior, summary of posterior by mean/median/credible interval/probability of specific hypotheses/parameter values (e.g., Pr(theta > 0), Pr(theta > MCID), etc.)

# Examples

## Examples

<br>

* All examples are taken from *Bayesian Approaches to Clinical Trials and Health-Care Evaluation* by Spiegelhalter et al. (2003)

<br>

* I hope to give some idea of the range and flexibility of Bayesian analysis

<br>

* We will focus on the 'What' and the 'Why', not on the 'How'

## Diagnostic testing

<br>

* Suppose have a new HIV test, which has 95% sensitivity and 98% specificity

* We want to use the test for screening, in a population with HIV prevalence of 1/1000

<br>

. . .

* What is the probability that someone has HIV, given that they have tested positive?

## Diagnostic testing

* Using Bayes' theorem:
$$\mathrm{Pr}(\text{HIV}^+\ |\ \text{test}^+) = \frac{\mathrm{Pr}(\text{test}^+\ |\ \text{HIV}^+)\ \mathrm{Pr}(\text{HIV}^+)}{\mathrm{Pr}(\text{test}^+)}$$

  * $\mathrm{Pr}(\text{test}^+\ |\ \text{HIV}^+)$ is the sensitivity, $0.95$
  
  * $\mathrm{Pr}(\text{HIV}^+)$ is $1 / 1000 = 0.001$
  
  * $\mathrm{Pr}(\text{test}^+)$ can be calculated as  
  $\mathrm{Pr}(\text{test}^+\ |\ \text{HIV}^-)\ \mathrm{Pr}(\text{HIV}^-) + \mathrm{Pr}(\text{test}^+\ |\ \text{HIV}^+)\ \mathrm{Pr}(\text{HIV}^+)$  
  $\ \ \ \  = 0.02 \times 0.999 + 0.95 \times 0.001 = 0.02093$

. . .

* Therefore,
$$\mathrm{Pr}(\text{HIV}^+\ |\ \text{test}^+) = \frac{0.95 \times 0.001}{0.02093} = 0.045$$

## Diagnostic testing

* To see how this works, consider the expected status of 100,000 individuals being screened

```{=html}
<table class="table" style="margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:center;"> </th>
   <th style="text-align:center;"> <b>HIV<sup>&minus;</sup></b> </th>
   <th style="text-align:center;"> <b>HIV<sup>+</sup></b> </th>
   <th style="text-align:center;"> </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:center;"> <b>Test<sup>&minus;</sup></b> </td>
   <td style="text-align:center;"> 97 902 </td>
   <td style="text-align:center;"> 5 </td>
   <td style="text-align:center;"> 97 903 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> <b>Test<sup>+</sup></b> </td>
   <td style="text-align:center;"> 1 998 </td>
   <td style="text-align:center;"> 95 </td>
   <td style="text-align:center;"> 2 093 </td>
  </tr>
  <tr>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 99 900 </td>
   <td style="text-align:center;"> 100 </td>
   <td style="text-align:center;"> 100 000 </td>
  </tr>
</tbody>
</table>
```

* As before, the probability of having HIV given a positive test can be calculated:
$$\mathrm{Pr}(\text{HIV}^+\ |\ \text{test}^+) = \frac{95}{2093} = 0.045$$

## Diagnostic testing

* More than 95% of those testing positive will not actually have HIV!

<br>

. . .

* Note that this is very sensitive to the base rate (the proportion who have HIV in the population being tested)

* If the test was used for diagnosis in people suspected of having HIV, such that, say $\mathrm{Pr}(\text{HIV}^+) = 0.2$, then
$$\mathrm{Pr}(\text{HIV}^+\ |\ \text{test}^+) = \frac{0.95 \times 0.2}{0.206} = 0.922$$

## Aside: 'The epidemiology of clinical trials'

* The same idea can be used to consider the 'diagnostic accuracy' of clinical trials in identifying truly effective treatments

* In early phase trials, in particular, most treatments tested are probably not effective

* Assume 10% of such trials are of effective treatments, and trials are designed for 80% power at 5% significance level

* The same calculations as before give $\mathrm{Pr}(\text{Effective}\ |\ \text{Significant result}) = 0.64$

* That is, even if all trials were conducted perfectly, no publication bias, etc., 36% of significant results are actually of ineffective treatments

## A simple RCT analysis

* The GREAT trial was a study of a new drug for early treatment after myocardial infarction, compared with placebo

* The primary outcome was 30-day mortality rate, with data:

```{=html}
<table class="table" style="margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:center;"> </th>
   <th style="text-align:center;"> <b>New</b> </th>
   <th style="text-align:center;"> <b>Placebo</b> </th>
   <th style="text-align:center;"> </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:center;"> <b>Death</b> </td>
   <td style="text-align:center;"> 13 </td>
   <td style="text-align:center;"> 23 </td>
   <td style="text-align:center;"> 36 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> <b>No death</b> </td>
   <td style="text-align:center;"> 150 </td>
   <td style="text-align:center;"> 125 </td>
   <td style="text-align:center;"> 275 </td>
  </tr>
  <tr>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 163 </td>
   <td style="text-align:center;"> 148 </td>
   <td style="text-align:center;"> 311 </td>
  </tr>
</tbody>
</table>
```

## A simple RCT analysis

* Standard analysis of these data gives an OR of (13 / 150) / (23 / 125) = 0.47, with 95% CI 0.24 to 0.97

  * That is, a fairly large reduction in mortality, just reaching statistical significance at the 5% level

. . . 

* From a Bayesian perspective, we need to consider what our prior belief is (was) on the plausible range of true effects, and how these results should cause us to revise those beliefs

. . . 

* Prior distribution was based on the subjective judgement of a senior cardiologist, informed by previous published and unpublished studies

  * 'an expectation of 15--20% reduction in mortality is highly plausible, while the extremes of no benefit and a 40% relative reduction are both unlikely'
  
  * Two initial thoughts on this prior:
  
    * If we are already confident that it is effective, why are we doing the trial?
    
    * This is a strong prior judgement, compared to the amount of information provided by the trial

. . . 

* Combining this prior with the observed data gives posterior estimate of 0.73 (95% credible interval 0.58 to 0.93)

## A simple RCT analysis

* Bayesian analysis can also be used to ask how the results of this trial should change the views of a reasonably skeptical observer

  * That is, with no prior view one way or the other, but believing large treatment effects are unlikely

* Assuming a prior centred on no effect (OR = 1), with 95% interval from 50% reduction (OR = 0.5) to 100% increase (OR = 2):

* Posterior OR = 0.70 (95% interval 0.43 to 1.14), i.e., no effect would still be considered reasonably plausible

# Bayesian analysis in practice

## Software

* Historically, conducting Bayesian analysis required specialised software/modelling languages
  * BUGS (Bayesian inference Using Gibbs Sampling)
  * JAGS (Just Another Gibbs Sampler)
  * Stan

. . .

* Most general-purpose statistical programs these days have (at least some) Bayesian methods available
  * R
    * `rstanarm`
    * `brms`
    * direct interface to Bayesian modelling languages with `rstan`, `rjags`
  * Stata (also StataStan)
  * SPSS ?

## Example - linear regression model

* We will use the `rstanarm` package in R for illustration
* This makes it very easy to run Bayesian analogues of several standard regression models (linear, logistic, etc.)
  * (Just as easy as running the standard classical models)

. . .

* Well, almost as easy
  * There are still a few Bayesian-specific issues to consider (prior distributions, computational options, etc.)

## (Not so) technical backgroun

* Bayesian estimation is based on Markov Chain Monte Carlo (MCMC) simulation
* We won't go into the details
  * Basically, we start with some initial guesses for the parameters, then keep adjusting these until we get to a stable distribution
  * Once we get to this stable range, the distribution of parameter 'guesses' is our posterior distribution
  * Checking how well this convergence has worked is a key part of model diagnostics

## Example - linear regression model

* Linear regression models in R (standard `lm()`, Bayesian analysis with `stan` and `stan_glm()`)
* Convergence diagnostics
* More substantive model checks -- i.e., does the model make sense?
  * Sensitivity to alternative priors
    * If the results are highly sensitive to different plausible priors, that should give us less confidence in our conclusions
  * Predictive accuracy
    * How well does the model predict the actual (distribution of) data?
* Model interpretation/analysis/reporting

## Further examples

* Other common regression models are easily replicated with `rstanarm` (or `brms`)
  * Logistic regression (binary outcomes)
  * Poisson regression (count outcomes)
* These packages can also do some more complicated models
  * Multinomial or ordinal outcomes
  * Mixed/random effects
* For more complex models, you will need to use Stan (or BUGS/JAGS) directly
  * `rstan` can run these models from within R
  * `brms` can be used to generate starter code, if the model is a variant of a `brms` model

## Further examples

* 8 Schools
  * Hierarchical Bayesian modelling

. . .

```{=html}
<table class="table" style="margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:center;"> <b>School</b> </th>
   <th style="text-align:center;"> <b>Mean estimate</b> </th>
   <th style="text-align:center;"> <b>Standard error</b> </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:center;"> A </td>
   <td style="text-align:center;"> 28 </td>
   <td style="text-align:center;"> 15 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> B </td>
   <td style="text-align:center;"> 8 </td>
   <td style="text-align:center;"> 10 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> C </td>
   <td style="text-align:center;"> -3 </td>
   <td style="text-align:center;"> 16 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> D </td>
   <td style="text-align:center;"> 7 </td>
   <td style="text-align:center;"> 11 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> E </td>
   <td style="text-align:center;"> -1 </td>
   <td style="text-align:center;"> 9 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> F </td>
   <td style="text-align:center;"> 1 </td>
   <td style="text-align:center;"> 11 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> G </td>
   <td style="text-align:center;"> 18 </td>
   <td style="text-align:center;"> 10 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> H </td>
   <td style="text-align:center;"> 12 </td>
   <td style="text-align:center;"> 18 </td>
  </tr>
</tbody>
</table>
```

. . .

::: {.absolute right=-50 top=30 style="border:1px solid black;padding:10px 20px;"}

What is our 'best'<br>
estimate of the true<br>
effect in School A?

:::

## Further examples

* Item Response Theory modelling
  * Rasch model: $\mathrm{logit}[\mathrm{Pr}(y_{ij} = 1 | \theta_j)] = \theta_j - \beta_i$
  * 2-parameter model: $\mathrm{logit}[\mathrm{Pr}(y_{ij} = 1 | \theta_j)] = \alpha_i(\theta_j - \beta_i)$
* The `edstan` package provides functions and Stan code to fit IRT models

## Frequentist vs. Bayesian

* Bayesian analysis:
  * Uses prior information (when available)
  * Accounts for uncertainty in parameters
  * Provides probability values and credible parameters with more intuitive (and meaningful) interpretation
  * Can provide more reliable estimates in small samples
  * Can estimate more complicated models and conduct more informative post-estimation analyses than traditional approaches
* But: can be more difficult to implement in practice
  * This is not necessarily a bad thing -- it might make us think about some of the underlying assumptions that can be swept under the carpet in traditional statistical analysis

## Summary

* Conducting Bayesian analysis requires a little more thought, and a little more confidence with statistical methods, than 'traditional' frequentist approaches
* Modern software packages make this a lot easier (and are getting better all the time)
* The payoff is more flexible modelling options, ability to incorporate relevant prior information, more robust estimates in small samples, and more meaningful analysis of uncertainty in parameter estimates

## References

* Recommended textbooks:
  * Introductory: *Doing Bayesian Data Analysis: A tutorial with R, JAGS, and Stan*, 2^nd^ Edition. John K. Kruschke (2015)
    * Mostly non-technical presentation of applied Bayesian analysis
    * e-Book available for download via the library
  * Intermediate: *Statistical Rethinking: A Bayesian Course with Examples in R and Stan*, 2^nd^ Edition. Richard McElreath (2020)
    * How to think about statistics in terms of data generating models
    * I couldn't find an e-Book version, but there are video lectures by the author on YouTube: <https://www.youtube.com/playlist?list=PLDcUM9US4XdPz-KxHM4XHt7uUVGWWVSus>
  * Advanced: *Bayesian Data Analysis*, 3^rd^ Edition. Andrew Gelman, John B. Carlin, Hal S. Stearn, David B. Dunson, Aki Vehtari, and Donald B. Rubin (2013)
    * Parts of this are quite advanced, but it also has lots of useful examples and applications
    * PDF version available from Gelman's website: <http://www.stat.columbia.edu/~gelman/book/>

## References

* Other useful resources:
  * Much of the background theory here follows *Bayesian Basics*, Michael Clark (2018): <https://m-clark.github.io/bayesian-basics/>
  * Stan and `rstan` both have extensive documentation, examples, etc. -- See <https://mc-stan.org>
  * Other R packages (`rstanarm`, `brms`, `edstan`, etc.) have their own documentation and usually good vignettes, tutorials, and/or examples
